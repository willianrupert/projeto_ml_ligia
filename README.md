# üõ°Ô∏è Detec√ß√£o de Fraudes Financeiras: Uma Abordagem de Pesquisa em IA Explic√°vel

## üìñ Introdu√ß√£o e Mentalidade de Pesquisa
Neste projeto, assumo o papel de Pesquisador em IA para o desafio individual da **Liga Acad√™mica de Intelig√™ncia Artificial (Ligia - UFPE)**. Meu objetivo central n√£o foi apenas alcan√ßar um score elevado no Leaderboard, mas construir uma solu√ß√£o robusta, reprodut√≠vel e totalmente explic√°vel, transformando o que poderia ser uma "caixa-preta" em um sistema transparente e fundamentado.

A detec√ß√£o de fraudes √© um problema cl√°ssico de **dados altamente desbalanceados** (onde as fraudes s√£o eventos rar√≠ssimos). Para enfrentar esse desafio, apliquei t√©cnicas de engenharia de features matem√°ticas, otimiza√ß√£o bayesiana e interpreta√ß√£o via Teoria dos Jogos.

---

## üèóÔ∏è 1. Estrutura do Projeto
Para garantir a qualidade de engenharia e a reprodutibilidade exigidas, organizei o reposit√≥rio de forma modular:

* **`data/`**: Cont√©m os conjuntos de dados `train.csv` e `test.csv` (protegidos via `.gitignore`).
* **`src/preprocessing.py`**: M√≥dulo contendo a l√≥gica de limpeza, transforma√ß√£o c√≠clica e escalonamento.
* **`src/model.py`**: Implementa√ß√£o da otimiza√ß√£o de hiperpar√¢metros (Optuna) e treinamento do XGBoost.
* **`notebooks/main.ipynb`**: Notebook de execu√ß√£o, an√°lise explorat√≥ria e gera√ß√£o de gr√°ficos de explicabilidade.
* **`requirements.txt`**: Lista de depend√™ncias para garantir que o ambiente seja id√™ntico em qualquer m√°quina.

---

## üî¨ 2. Metodologia e Decis√µes T√©cnicas

### 2.1 Engenharia de Features: O Tratamento C√≠clico do Tempo
Uma das minhas principais decis√µes foi o tratamento da vari√°vel `Time`. Em vez de trat√°-la como um contador linear de segundos, eu a transformei em coordenadas de **Seno e Cosseno** ($sin(t)$ e $cos(t)$).
* **Por que?** Em um contador linear, as 23:59h e as 00:01h parecem distantes numericamente, quando na verdade s√£o vizinhas. Ao mapear o tempo em um c√≠rculo unit√°rio, eu permito que o modelo capture padr√µes de sazonalidade (como fraudes que ocorrem mais frequentemente de madrugada) de forma cont√≠nua e natural.

### 2.2 Escalonamento Robusto e Preven√ß√£o de *Data Leakage*
Para a vari√°vel `Amount` (valor da transa√ß√£o), optei pelo **`RobustScaler`**.
* **Por que?** Fraudes costumam apresentar valores discrepantes (outliers). O `RobustScaler` utiliza a mediana e o intervalo interquartil, tornando o escalonamento imune a esses outliers que poderiam distorcer uma normaliza√ß√£o padr√£o.
* **Rigor Cient√≠fico:** Implementei uma l√≥gica rigorosa para evitar o **Vazamento de Dados (Data Leakage)**. Eu treinei o escalonador apenas nos dados de treino (`fit_transform`) e utilizei esse "molde" apenas para transformar os dados de valida√ß√£o e teste (`transform`), garantindo que nenhuma informa√ß√£o do futuro influenciasse o aprendizado.

---

## ü§ñ 3. Modelagem e Otimiza√ß√£o

### 3.1 XGBoost vs. Outras Arquiteturas
Embora o material de apoio discuta Random Forests (que usam *Bagging*), eu escolhi o **XGBoost (Gradient Boosting)**.
* **Fundamenta√ß√£o:** O Gradient Boosting √© sequencial: cada nova √°rvore de decis√£o foca especificamente em corrigir os erros residuais das √°rvores anteriores. Em um problema onde a fraude √© a "agulha no palheiro", essa natureza de corre√ß√£o de erros sequencial √© superior √† vota√ß√£o independente das Random Forests.

### 3.2 Otimiza√ß√£o Bayesiana com Optuna
Em vez de testar par√¢metros manualmente, utilizei o **Optuna** para realizar uma busca inteligente no espa√ßo de hiperpar√¢metros.
* **scale_pos_weight:** O par√¢metro mais cr√≠tico. O Optuna encontrou um valor de aproximadamente **89.8**, o que significa que o modelo d√° um peso quase 90 vezes maior para a classe de fraudes, compensando matematicamente o desbalanceamento sem a necessidade de criar dados sint√©ticos (SMOTE).

---

## üìä 4. Resultados e M√©tricas de Neg√≥cio

### 4.1 ROC-AUC: O Crit√©rio de Avalia√ß√£o
Conforme o edital, otimizei o modelo para a m√©trica **ROC-AUC**. Meu modelo atingiu um score de **0.9872** na valida√ß√£o local, demonstrando uma alt√≠ssima capacidade de ordenar transa√ß√µes por risco.

### 4.2 M√©tricas de Neg√≥cio (Recall e Precis√£o)
No meu relat√≥rio t√©cnico, decidi n√£o olhar apenas para a probabilidade, mas sim para o impacto real. Ajustando o limiar de decis√£o (*threshold*) para **0.3**, obtive:
* **Recall de 80%:** Identificamos 8 em cada 10 fraudes.
* **Precis√£o de 88%:** Mantivemos o erro de bloquear clientes leg√≠timos em um n√≠vel muito baixo.

---

## üîé 5. Explicabilidade (XAI) com SHAP
Para garantir que o modelo n√£o seja uma "Caixa-Preta" (exig√™ncia do edital), utilizei o **SHAP (SHapley Additive exPlanations)**.
* **An√°lise Global:** O gr√°fico `summary_plot` revelou que as vari√°veis **V4, V14 e V12** s√£o as mais influentes. Valores baixos em V14 e V12 aumentam drasticamente a suspeita de fraude.
* **An√°lise Local:** Gere gr√°ficos de cascata (*Waterfall*) para explicar transa√ß√µes individuais, provando exatamente quais caracter√≠sticas levaram o modelo a considerar aquela opera√ß√£o espec√≠fica como fraudulenta.

---

## üèÅ Conclus√£o e Reprodutibilidade
Para garantir a integridade cient√≠fica, fixei a semente aleat√≥ria (**seed/random_state**) em **42** em todas as etapas, desde a separa√ß√£o dos dados at√© o treinamento do XGBoost, conforme solicitado pelo edital.

Este trabalho representa uma busca cont√≠nua em unir a engenharia de software √† pesquisa cient√≠fica em IA com precis√£o, motivando-me a entregar uma solu√ß√£o que n√£o apenas performa, mas que √© justific√°vel e segura.